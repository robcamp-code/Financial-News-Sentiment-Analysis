{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cbbf4c3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975a4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy import displacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1e1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52202a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/FinancialNewsData.csv\", encoding='Windows-1252', names=['Label', 'Headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be94b01",
   "metadata": {},
   "source": [
    "# Extracting Features from Parts of Speech, Bigrams, and Trigrams\n",
    "\n",
    "Bag of words suffers from the curse of dimensionality quite a bit. Many words only appear in one or two headlines. So here we will extract features based on the part of speech that the word is tagged with. This is a very simple task with spacy and the parts of speech that we are interested in are nouns, verbs, adjectives, adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c57057",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05bd91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Headline = df.Headline.apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84972c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_counter = Counter()\n",
    "verb_counter = Counter()\n",
    "adj_counter = Counter()\n",
    "adverb_counter = Counter()\n",
    "\n",
    "bigram_counter = Counter()\n",
    "trigram_counter = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a77487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_counter(doc):\n",
    "    tokens = [token for token in doc if not token.is_punct]\n",
    "    \n",
    "    building = [i for i in tokens if (i.lower_ == 'building' and i.pos == 'VERB')]\n",
    "    \n",
    "        \n",
    "        \n",
    "    bi_grams = list(bigrams(tokens))\n",
    "    tri_grams = list(trigrams(tokens))\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token.pos_ == 'NOUN':\n",
    "            noun_counter[token.lower_] += 1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb_counter[token.lower_] += 1\n",
    "            \n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj_counter[token.lower_] += 1\n",
    "        \n",
    "        elif token.pos_ == 'ADV':\n",
    "            adverb_counter[token.lower_] += 1\n",
    "    \n",
    "    for bi in bi_grams:\n",
    "        bis = list([bi[0].text, bi[1].text])\n",
    "        # Ensure both words in the bigram are not stop words i.e (is, the) or (is, a) will not be included\n",
    "        if ('`' not in bis) and (\"'s\" not in bis) and not (bi[0].is_stop and bi[1].is_stop):\n",
    "            bigram_counter[bi[0].lower_, bi[1].lower_] += 1\n",
    "    \n",
    "    for tri in tri_grams:\n",
    "        tris = list([tri[0].text, tri[1].text, tri[2].text])\n",
    "        # Ensure all three words in trigram are not all stop words i.e (will, be, a) and (and, is, a) will not be included\n",
    "        if ('`' not in tris) and (\"'s\" not in tris) and not (tri[0].is_stop and tri[1].is_stop and tri[2].is_stop) :\n",
    "            trigram_counter[(tri[0].lower_, tri[1].lower_, tri[2].lower_)] += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "604e07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = df.Headline.apply(lambda x: increment_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0529071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(verb=200, adj=200, adv=200, noun=200, bigram=100, trigram=100):\n",
    "    \n",
    "    column_names = [\"Headline\"]\n",
    "    \n",
    "    # loop through the X most common verbs and add them to column names\n",
    "    for i in verb_counter.most_common(verb):\n",
    "        column_names.append(i[0] + \"_VERB\")\n",
    "    \n",
    "    for i in adj_counter.most_common(adj):\n",
    "        column_names.append(i[0] + \"_ADJ\")\n",
    "    \n",
    "    for i in adverb_counter.most_common(adv):\n",
    "        column_names.append(i[0] + \"_ADV\")\n",
    "        \n",
    "    for i in noun_counter.most_common(noun):\n",
    "        column_names.append(i[0] + \"_NOUN\")\n",
    "        \n",
    "    #same for bigrams\n",
    "    for i in bigram_counter.most_common(bigram):\n",
    "        column_names.append(str(i[0]))\n",
    "    #same for trigrams\n",
    "    for i in trigram_counter.most_common(trigram):\n",
    "        column_names.append(str(i[0]))\n",
    "    \n",
    "    #return empty dataframe with column names\n",
    "    return pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e649ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e012a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>said_VERB</th>\n",
       "      <th>m_VERB</th>\n",
       "      <th>operating_VERB</th>\n",
       "      <th>be_VERB</th>\n",
       "      <th>compared_VERB</th>\n",
       "      <th>based_VERB</th>\n",
       "      <th>according_VERB</th>\n",
       "      <th>has_VERB</th>\n",
       "      <th>increased_VERB</th>\n",
       "      <th>...</th>\n",
       "      <th>('stock', 'exchange', 'release')</th>\n",
       "      <th>('a', 'net', 'loss')</th>\n",
       "      <th>('a', 'net', 'profit')</th>\n",
       "      <th>('of', 'the', 'board')</th>\n",
       "      <th>('net', 'sales', 'increased')</th>\n",
       "      <th>('in', 'the', 'fourth')</th>\n",
       "      <th>('fourth', 'quarter', 'of')</th>\n",
       "      <th>('period', 'in', '2007')</th>\n",
       "      <th>('month', 'period', 'increased')</th>\n",
       "      <th>('to', 'the', 'corresponding')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Headline, said_VERB, m_VERB, operating_VERB, be_VERB, compared_VERB, based_VERB, according_VERB, has_VERB, increased_VERB, rose_VERB, expected_VERB, decreased_VERB, signed_VERB, have_VERB, announced_VERB, is_VERB, including_VERB, increase_VERB, includes_VERB, fell_VERB, reported_VERB, made_VERB, totalled_VERB, include_VERB, expects_VERB, estimated_VERB, totaled_VERB, was_VERB, says_VERB, start_VERB, developed_VERB, sell_VERB, completed_VERB, leading_VERB, agreed_VERB, had_VERB, added_VERB, amounted_VERB, acquired_VERB, continue_VERB, provide_VERB, make_VERB, awarded_VERB, grew_VERB, used_VERB, won_VERB, following_VERB, related_VERB, headquartered_VERB, use_VERB, been_VERB, provides_VERB, are_VERB, owned_VERB, delivered_VERB, built_VERB, set_VERB, started_VERB, take_VERB, sold_VERB, fixed_VERB, posted_VERB, deliver_VERB, issued_VERB, expand_VERB, held_VERB, received_VERB, decided_VERB, buy_VERB, using_VERB, excluding_VERB, published_VERB, employs_VERB, paid_VERB, acquire_VERB, existing_VERB, scheduled_VERB, provided_VERB, remain_VERB, disclosed_VERB, supply_VERB, operates_VERB, combined_VERB, improve_VERB, developing_VERB, generated_VERB, listed_VERB, located_VERB, established_VERB, enable_VERB, plans_VERB, reports_VERB, went_VERB, covers_VERB, included_VERB, invest_VERB, improved_VERB, makes_VERB, closed_VERB, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1001 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94877e",
   "metadata": {},
   "source": [
    "Remove duplicate columns and instantiate everything to 0 so it can be incremented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "608bba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['Headline'] = df.Headline\n",
    "feature_df.iloc[:, 1:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b896a93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_VERB', 'building_NOUN'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.filter(regex='building').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "784cc3da",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 544),\n",
       " ('m', 252),\n",
       " ('operating', 220),\n",
       " ('be', 189),\n",
       " ('compared', 149),\n",
       " ('based', 127),\n",
       " ('according', 123),\n",
       " ('has', 110),\n",
       " ('increased', 109),\n",
       " ('rose', 102),\n",
       " ('expected', 83),\n",
       " ('decreased', 79),\n",
       " ('signed', 75),\n",
       " ('have', 72),\n",
       " ('announced', 70),\n",
       " ('is', 69),\n",
       " ('including', 69),\n",
       " ('increase', 57),\n",
       " ('includes', 56),\n",
       " ('fell', 55),\n",
       " ('reported', 53),\n",
       " ('made', 53),\n",
       " ('totalled', 51),\n",
       " ('include', 50),\n",
       " ('expects', 49),\n",
       " ('estimated', 49),\n",
       " ('totaled', 48),\n",
       " ('was', 47),\n",
       " ('says', 45),\n",
       " ('start', 42),\n",
       " ('developed', 41),\n",
       " ('sell', 41),\n",
       " ('completed', 41),\n",
       " ('leading', 39),\n",
       " ('agreed', 38),\n",
       " ('had', 38),\n",
       " ('added', 38),\n",
       " ('amounted', 37),\n",
       " ('acquired', 37),\n",
       " ('continue', 37),\n",
       " ('provide', 36),\n",
       " ('make', 36),\n",
       " ('awarded', 35),\n",
       " ('grew', 34),\n",
       " ('used', 34),\n",
       " ('won', 34),\n",
       " ('following', 33),\n",
       " ('related', 33),\n",
       " ('headquartered', 33),\n",
       " ('use', 33),\n",
       " ('been', 32),\n",
       " ('provides', 32),\n",
       " ('are', 32),\n",
       " ('owned', 31),\n",
       " ('delivered', 31),\n",
       " ('built', 31),\n",
       " ('set', 31),\n",
       " ('started', 31),\n",
       " ('take', 30),\n",
       " ('sold', 29),\n",
       " ('fixed', 28),\n",
       " ('posted', 28),\n",
       " ('deliver', 28),\n",
       " ('issued', 28),\n",
       " ('expand', 27),\n",
       " ('held', 27),\n",
       " ('received', 27),\n",
       " ('decided', 27),\n",
       " ('buy', 27),\n",
       " ('using', 26),\n",
       " ('excluding', 26),\n",
       " ('published', 25),\n",
       " ('employs', 25),\n",
       " ('paid', 24),\n",
       " ('acquire', 24),\n",
       " ('existing', 24),\n",
       " ('scheduled', 24),\n",
       " ('provided', 24),\n",
       " ('remain', 24),\n",
       " ('disclosed', 24),\n",
       " ('supply', 23),\n",
       " ('operates', 23),\n",
       " ('combined', 23),\n",
       " ('improve', 22),\n",
       " ('developing', 22),\n",
       " ('generated', 22),\n",
       " ('listed', 22),\n",
       " ('located', 22),\n",
       " ('established', 22),\n",
       " ('enable', 22),\n",
       " ('plans', 21),\n",
       " ('reports', 21),\n",
       " ('went', 21),\n",
       " ('covers', 21),\n",
       " ('included', 21),\n",
       " ('invest', 21),\n",
       " ('improved', 21),\n",
       " ('makes', 21),\n",
       " ('closed', 20),\n",
       " ('become', 20),\n",
       " ('continued', 20),\n",
       " ('bought', 20),\n",
       " ('build', 20),\n",
       " ('enables', 20),\n",
       " ('making', 20),\n",
       " ('focus', 20),\n",
       " ('cut', 20),\n",
       " ('growing', 19),\n",
       " ('carried', 19),\n",
       " ('offers', 19),\n",
       " ('subscribed', 19),\n",
       " ('known', 18),\n",
       " ('providing', 18),\n",
       " ('aims', 18),\n",
       " ('pay', 18),\n",
       " ('concerning', 18),\n",
       " ('working', 17),\n",
       " ('representing', 17),\n",
       " ('estimates', 17),\n",
       " ('offer', 17),\n",
       " ('owns', 17),\n",
       " ('told', 17),\n",
       " ('given', 17),\n",
       " ('narrowed', 17),\n",
       " ('develop', 16),\n",
       " ('strengthen', 16),\n",
       " ('remaining', 16),\n",
       " ('declined', 16),\n",
       " ('cover', 16),\n",
       " ('starting', 16),\n",
       " ('transfer', 16),\n",
       " ('came', 15),\n",
       " ('planned', 15),\n",
       " ('continuing', 15),\n",
       " ('approved', 15),\n",
       " ('dropped', 15),\n",
       " ('bring', 15),\n",
       " ('raised', 14),\n",
       " ('stood', 14),\n",
       " ('designed', 14),\n",
       " ('selling', 14),\n",
       " ('serve', 14),\n",
       " ('planning', 14),\n",
       " ('produced', 14),\n",
       " ('launched', 14),\n",
       " ('managing', 13),\n",
       " ('see', 13),\n",
       " ('seen', 13),\n",
       " ('controlled', 13),\n",
       " ('registered', 13),\n",
       " ('entered', 13),\n",
       " ('holding', 13),\n",
       " ('gave', 13),\n",
       " ('gives', 13),\n",
       " ('holds', 13),\n",
       " ('lay', 13),\n",
       " ('cutting', 13),\n",
       " ('establish', 13),\n",
       " ('reached', 12),\n",
       " ('taken', 12),\n",
       " ('return', 12),\n",
       " ('ordered', 12),\n",
       " ('acquiring', 12),\n",
       " ('recorded', 12),\n",
       " ('issue', 12),\n",
       " ('reduce', 12),\n",
       " ('give', 12),\n",
       " ('ensure', 12),\n",
       " ('released', 12),\n",
       " ('launch', 12),\n",
       " ('come', 12),\n",
       " ('disclose', 12),\n",
       " ('reach', 11),\n",
       " ('propose', 11),\n",
       " ('proposed', 11),\n",
       " ('building', 11),\n",
       " ('corresponding', 11),\n",
       " ('produce', 11),\n",
       " ('raise', 11),\n",
       " ('receive', 11),\n",
       " ('transferred', 11),\n",
       " ('do', 11),\n",
       " ('accounted', 11),\n",
       " ('consists', 11),\n",
       " ('hit', 11),\n",
       " ('create', 11),\n",
       " ('publish', 11),\n",
       " ('selected', 11),\n",
       " ('producing', 11),\n",
       " ('managed', 11),\n",
       " ('operate', 11),\n",
       " ('going', 11),\n",
       " ('directed', 11),\n",
       " ('found', 11),\n",
       " ('laid', 10),\n",
       " ('founded', 10),\n",
       " ('opened', 10),\n",
       " ('release', 10),\n",
       " ('supports', 10),\n",
       " ('increasing', 10)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_counter.most_common(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af71816",
   "metadata": {},
   "source": [
    "As you can see the same word could be tagged as a noun in one sentence but tagged as a verb in another. This happened on 30 occasions, so our final feature df has 970 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94f3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_df(index, doc):\n",
    "    \n",
    "    tokens = [token for token in doc if not token.is_punct]\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    bi_grams = list(bigrams(tokens))\n",
    "    tri_grams = list(trigrams(tokens))\n",
    "    \n",
    "    for token in tokens:\n",
    "        \n",
    "        if token.pos_ == \"NOUN\":\n",
    "            if token.lower_ + \"_NOUN\" in list(feature_df.columns):\n",
    "                feature_df.loc[index, token.lower_ + \"_NOUN\"] += 1\n",
    "        \n",
    "        elif token.pos_ == \"VERB\":\n",
    "            if token.lower_ + \"_VERB\" in list(feature_df.columns):\n",
    "                feature_df.loc[index, token.lower_ + \"_VERB\"] += 1\n",
    "        \n",
    "        elif token.pos_ == \"ADJ\":    \n",
    "            if token.lower_ + \"_ADJ\" in list(feature_df.columns):\n",
    "                feature_df.loc[index, token.lower_ + \"_ADJ\"] += 1\n",
    "        \n",
    "        elif token.pos_ == \"ADV\":\n",
    "            if token.lower_ + \"_ADV\" in list(feature_df.columns):\n",
    "                feature_df.loc[index, token.lower_ + \"_ADV\"] += 1\n",
    "    \n",
    "    for bi in bi_grams:\n",
    "        bis = str((bi[0].lower_, bi[1].lower_))\n",
    "        # Ensure both words in the bigram are not stop words i.e (is, the) or (is, a) will not be included\n",
    "        if bis in feature_df.columns:\n",
    "            feature_df.loc[index, str((bi[0].lower_, bi[1].lower_))] += 1\n",
    "    \n",
    "    for tri in tri_grams:\n",
    "        tris = str((tri[0].lower_, tri[1].lower_, tri[2].lower_))\n",
    "        # Ensure all three words in trigram are not all stop words i.e (will, be, a) and (and, is, a) will not be included\n",
    "        if tris in feature_df.columns :\n",
    "            feature_df.loc[index, tris] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fdf5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each headline and increment the corresponding column\n",
    "_ = feature_df['Headline'].apply(lambda x: increment_df(feature_df[feature_df.Headline == x].index[0], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26f1e4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80mn_ADV              1\n",
       "aggressively_ADV      1\n",
       "geographically_ADV    1\n",
       "markedly_ADV          1\n",
       "broad_ADV             1\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df.iloc[:, 1:].sum().sort_values(ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce5b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df.drop(\"Headline\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff8943",
   "metadata": {},
   "source": [
    "All columns have atleast 1 occurance of the word. We do still have a very sparse dataframe; but not as sparce as the bag of words approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1683ee",
   "metadata": {},
   "source": [
    "# Save Features to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5416843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Objects/pos.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(feature_df, \"Objects/pos.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6084696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
