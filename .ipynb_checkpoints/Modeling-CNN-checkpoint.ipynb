{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27d8932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eac7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62617abd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Objects/labels.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0q/2w6362bn3v11r3hw5198hcvw0000gn/T/ipykernel_64951/2387322579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Objects/labels.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Objects/padded_glove_embeddings.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Objects/labels.pt'"
     ]
    }
   ],
   "source": [
    "y = torch.load(\"Objects/labels.pt\")\n",
    "X = torch.load(\"Objects/padded_glove_embeddings.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95412bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_samples = X.size(0)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a006559",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c2e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = random_split(data, [4000, 846])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a55c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfae896",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ca89024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architechture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,1,(1,300), stride=1)\n",
    "        self.conv2 = nn.Conv2d(1,1,(2,1), stride=1)\n",
    "        self.conv3 = nn.Conv1d(1,1,(3,300), stride=1)\n",
    "        self.pool1 = nn.MaxPool2d((4,1))\n",
    "        self.pool2 = nn.AvgPool2d((4,1))\n",
    "        \n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(5, 3)\n",
    "    def forward(self, x):\n",
    "        #output = self.conv1(x)\n",
    "        #output = self.conv2(output)\n",
    "        output = self.activation(self.conv1(x))\n",
    "        output = self.activation(self.pool2(output))\n",
    "        output = self.activation(self.conv2(output))\n",
    "        output = self.activation(self.pool2(output))\n",
    "        output = self.flat(output)\n",
    "        output = self.activation(self.linear1(output))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8e6708d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c32d9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypereparameters\n",
    "num_epochs = 10\n",
    "n_total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e259b649",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0732002258300781 --- epoch: 1, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.1660754680633545 --- epoch: 1, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0791847705841064 --- epoch: 1, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9290782809257507 --- epoch: 1, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0064963102340698 --- epoch: 2, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0047452449798584 --- epoch: 2, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.1487127542495728 --- epoch: 2, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0052978992462158 --- epoch: 2, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.1471436023712158 --- epoch: 3, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8148767352104187 --- epoch: 3, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9945775270462036 --- epoch: 3, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9750156402587891 --- epoch: 3, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0771434307098389 --- epoch: 4, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.663447916507721 --- epoch: 4, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.7644211053848267 --- epoch: 4, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8760408163070679 --- epoch: 4, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.7482778429985046 --- epoch: 5, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.198583960533142 --- epoch: 5, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8605527877807617 --- epoch: 5, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.7418631315231323 --- epoch: 5, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8620768785476685 --- epoch: 6, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0973889827728271 --- epoch: 6, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9865762591362 --- epoch: 6, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.0986695289611816 --- epoch: 6, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.09987211227417 --- epoch: 7, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.1004819869995117 --- epoch: 7, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8510198593139648 --- epoch: 7, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8477224111557007 --- epoch: 7, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.495779275894165 --- epoch: 8, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9679759740829468 --- epoch: 8, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8430835008621216 --- epoch: 8, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.7104922533035278 --- epoch: 8, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.7061837911605835 --- epoch: 9, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.8405879139900208 --- epoch: 9, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9802802801132202 --- epoch: 9, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.697830080986023 --- epoch: 9, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.9796924591064453 --- epoch: 10, step: 200/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.7001875042915344 --- epoch: 10, step: 400/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 0.5585952997207642 --- epoch: 10, step: 600/880\n",
      "torch.Size([5, 1, 88, 300])\n",
      "Loss: 1.3969749212265015 --- epoch: 10, step: 800/880\n",
      "torch.Size([5, 1, 88, 300])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (feature, label) in enumerate(train_loader):\n",
    "        feature = feature.to(device)\n",
    "        label = label.to(device)\n",
    "        feature = feature.view(batch_size, 1, 88, 300)\n",
    "        #forward pass\n",
    "        outputs = model(feature.float())\n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "        #back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f'Loss: {loss} --- epoch: {epoch+1}, step: {i+1}/{n_total_steps}') \n",
    "            print(feature.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6a8a1747",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    predictions = torch.tensor([])\n",
    "    labels = torch.tensor([])\n",
    "    for feature, label in test_loader:\n",
    "        feature = feature.to(device)\n",
    "\n",
    "        feature = feature.view(feature.size()[0],1,88,300)\n",
    "        label = label.to(device)\n",
    "        outputs = model(feature.float())\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        predictions = torch.cat([predictions, predicted])\n",
    "        labels = torch.cat([label, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d204818c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5942)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(predictions == labels).sum() / 446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7923395b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40ebeaa5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 1., 1., 1., 2., 1., 1., 0., 1., 2., 1., 0., 2., 1., 1.,\n",
       "        2., 1., 2., 1., 1., 1., 2., 1., 2., 1., 1., 1., 2., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 2., 2., 0., 1., 0., 1., 0., 1., 1., 1., 1., 2., 0., 2., 0., 1.,\n",
       "        1., 1., 1., 2., 1., 1., 2., 2., 1., 2., 0., 2., 1., 0., 0., 1., 2., 1.,\n",
       "        1., 2., 2., 1., 2., 2., 0., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 1.,\n",
       "        1., 1., 1., 1., 2., 1., 1., 2., 0., 1., 1., 0., 1., 1., 2., 1., 2., 1.,\n",
       "        1., 1., 2., 2., 1., 2., 2., 2., 2., 2., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 2., 2., 1., 1., 2., 0., 1., 0., 1., 1., 2., 2., 0., 1., 1., 2.,\n",
       "        1., 2., 1., 1., 1., 0., 1., 1., 2., 1., 1., 2., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 2., 0., 1., 1., 1., 0., 1., 0., 2., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 2., 2., 2., 2., 2., 1., 1., 0.,\n",
       "        1., 1., 0., 1., 1., 1., 1., 2., 1., 2., 2., 2., 0., 1., 1., 2., 1., 0.,\n",
       "        1., 1., 1., 2., 1., 0., 1., 1., 1., 2., 2., 2., 1., 1., 2., 1., 2., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 2., 1., 2., 1., 0., 1., 1., 2., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 2., 2., 1., 1., 1., 2., 2., 0., 1., 1., 1.,\n",
       "        1., 1., 2., 1., 1., 1., 1., 1., 0., 1., 1., 2., 0., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 0., 2., 1., 1., 1., 2., 1., 1., 0., 1., 2., 1., 0., 2., 1., 1.,\n",
       "        1., 1., 0., 2., 1., 1., 1., 2., 0., 1., 1., 0., 1., 0., 2., 2., 1., 1.,\n",
       "        0., 1., 2., 1., 0., 2., 1., 2., 0., 1., 1., 0., 1., 1., 2., 2., 1., 1.,\n",
       "        0., 2., 2., 1., 1., 1., 1., 2., 0., 2., 1., 1., 0., 1., 1., 2., 2., 2.,\n",
       "        1., 1., 0., 2., 1., 2., 1., 2., 0., 1., 2., 2., 2., 1., 1., 1., 1., 2.,\n",
       "        1., 1., 2., 1., 0., 1., 1., 2., 2., 2., 2., 1., 1., 2., 0., 0., 1., 2.,\n",
       "        1., 1., 2., 2., 1., 2., 1., 1., 1., 1., 1., 1., 2., 1., 1., 2., 1., 1.,\n",
       "        0., 2., 2., 1., 1., 1., 2., 1., 1., 1., 0., 0., 1., 1., 1., 2., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7834d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
